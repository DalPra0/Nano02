import Foundation
import Vision
import UIKit
import CoreGraphics

class FaceDetectionService {
    
    struct FaceDetectionResult {
        let boundingBox: CGRect
        let landmarks: VNFaceLandmarks2D
        let confidence: Float
        
        let leftEye: [CGPoint]
        let rightEye: [CGPoint] 
        let nose: [CGPoint]
        let outerLips: [CGPoint]
        let faceContour: [CGPoint]
    }
    
    static let shared = FaceDetectionService()
    private init() {}
    
    func detectFace(in image: UIImage, completion: @escaping (Result<FaceDetectionResult, Error>) -> Void) {
        
        print("üëÅÔ∏è FaceDetectionService: Iniciando detec√ß√£o facial...")
        
        guard let cgImage = image.cgImage else {
            print("‚ùå Erro: N√£o foi poss√≠vel converter UIImage para CGImage")
            completion(.failure(FaceDetectionError.imageConversionFailed))
            return
        }
        
        let request = VNDetectFaceLandmarksRequest { request, error in
            self.handleFaceDetectionResult(request: request, error: error, completion: completion)
        }
        
        request.revision = VNDetectFaceLandmarksRequestRevision3
        
        DispatchQueue.global(qos: .userInitiated).async {
            let handler = VNImageRequestHandler(cgImage: cgImage, options: [:])
            
            do {
                try handler.perform([request])
                print("‚úÖ Request de detec√ß√£o facial executado")
            } catch {
                print("‚ùå Erro ao executar request: \(error)")
                completion(.failure(error))
            }
        }
    }
    
    private func handleFaceDetectionResult(
        request: VNRequest,
        error: Error?,
        completion: @escaping (Result<FaceDetectionResult, Error>) -> Void
    ) {
        if let error = error {
            print("‚ùå Erro na detec√ß√£o facial: \(error)")
            DispatchQueue.main.async {
                completion(.failure(error))
            }
            return
        }
        
        guard let results = request.results as? [VNFaceObservation] else {
            print("‚ùå Nenhum resultado de detec√ß√£o facial")
            DispatchQueue.main.async {
                completion(.failure(FaceDetectionError.noFaceDetected))
            }
            return
        }
        
        guard let faceObservation = results.first else {
            print("‚ùå Nenhum rosto detectado")
            DispatchQueue.main.async {
                completion(.failure(FaceDetectionError.noFaceDetected))
            }
            return
        }
        
        print("‚úÖ Rosto detectado com confian√ßa: \(faceObservation.confidence)")
        
        guard let landmarks = faceObservation.landmarks else {
            print("‚ùå Landmarks n√£o dispon√≠veis")
            DispatchQueue.main.async {
                completion(.failure(FaceDetectionError.landmarksNotAvailable))
            }
            return
        }
        
        let result = self.extractLandmarkPoints(
            from: landmarks,
            boundingBox: faceObservation.boundingBox,
            confidence: faceObservation.confidence
        )
        
        print("üéØ Landmarks extra√≠dos:")
        print("   ‚Ä¢ Olho esquerdo: \(result.leftEye.count) pontos")
        print("   ‚Ä¢ Olho direito: \(result.rightEye.count) pontos")
        print("   ‚Ä¢ Nariz: \(result.nose.count) pontos")
        print("   ‚Ä¢ L√°bios: \(result.outerLips.count) pontos")
        print("   ‚Ä¢ Contorno: \(result.faceContour.count) pontos")
        
        DispatchQueue.main.async {
            completion(.success(result))
        }
    }
    
    private func extractLandmarkPoints(
        from landmarks: VNFaceLandmarks2D,
        boundingBox: CGRect,
        confidence: Float
    ) -> FaceDetectionResult {
        
        func normalizedToPoints(_ region: VNFaceLandmarkRegion2D?) -> [CGPoint] {
            guard let region = region else { return [] }
            
            return region.normalizedPoints.map { point in
                CGPoint(
                    x: point.x * boundingBox.width + boundingBox.minX,
                    y: point.y * boundingBox.height + boundingBox.minY
                )
            }
        }
        
        let leftEye = normalizedToPoints(landmarks.leftEye)
        let rightEye = normalizedToPoints(landmarks.rightEye)
        let nose = normalizedToPoints(landmarks.nose)
        let outerLips = normalizedToPoints(landmarks.outerLips)
        let faceContour = normalizedToPoints(landmarks.faceContour)
        
        return FaceDetectionResult(
            boundingBox: boundingBox,
            landmarks: landmarks,
            confidence: confidence,
            leftEye: leftEye,
            rightEye: rightEye,
            nose: nose,
            outerLips: outerLips,
            faceContour: faceContour
        )
    }
    
    
    func convertVisionToImageCoordinates(
        _ point: CGPoint,
        imageSize: CGSize
    ) -> CGPoint {
        return CGPoint(
            x: point.x * imageSize.width,
            y: (1 - point.y) * imageSize.height
        )
    }
    
    func isDetectionQualityGood(_ result: FaceDetectionResult) -> Bool {
        let hasGoodConfidence = result.confidence > 0.7
        let hasEssentialLandmarks = !result.leftEye.isEmpty && 
                                   !result.rightEye.isEmpty && 
                                   !result.nose.isEmpty
        
        print("üéØ Qualidade da detec√ß√£o:")
        print("   ‚Ä¢ Confian√ßa: \(result.confidence) (>\(0.7) = \(hasGoodConfidence))")
        print("   ‚Ä¢ Landmarks essenciais: \(hasEssentialLandmarks)")
        
        return hasGoodConfidence && hasEssentialLandmarks
    }
}

enum FaceDetectionError: LocalizedError {
    case imageConversionFailed
    case noFaceDetected
    case landmarksNotAvailable
    case lowQualityDetection
    
    var errorDescription: String? {
        switch self {
        case .imageConversionFailed:
            return "N√£o foi poss√≠vel processar a imagem"
        case .noFaceDetected:
            return "Nenhum rosto foi detectado na foto"
        case .landmarksNotAvailable:
            return "N√£o foi poss√≠vel detectar caracter√≠sticas faciais"
        case .lowQualityDetection:
            return "Qualidade da detec√ß√£o muito baixa. Tente uma foto com melhor ilumina√ß√£o"
        }
    }
}
